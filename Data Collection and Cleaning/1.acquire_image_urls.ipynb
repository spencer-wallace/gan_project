{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "curious-jefferson",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "micro-excellence",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial API request \n",
    "#necesary to obtain object IDs which will be used in second pass to obtain image urls\n",
    "r = requests.get('https://collectionapi.metmuseum.org/public/collection/v1/objects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-membership",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract object IDs as a list\n",
    "indices = r.json()\n",
    "ident = indices['objectIDs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capital-collect",
   "metadata": {},
   "outputs": [],
   "source": [
    "#useful counter for if any issues arise for restarting from where error was thrown\n",
    "#given that this is a multiday process to scrape, its less of a question of if and more a question of when\n",
    "total = 0\n",
    "#function to obtain image links\n",
    "def get_objects_with_info(start_num):\n",
    "    #results stored as dict\n",
    "    #since some objects have more than 1 image, the other_links list stores any supplemental photos\n",
    "    image_items= {'id': [], 'link': [], 'other_links':[]}\n",
    "    #iterate through object IDs from given start which is intially zero\n",
    "    for i in tqdm(ident[start_num:]):\n",
    "        #API throws errors with some regularity so try/except was important\n",
    "        try:\n",
    "            #calls second API using specific object ID to get image urls\n",
    "            o = api_call(f'https://collectionapi.metmuseum.org/public/collection/v1/objects/{i}')\n",
    "            item = o.json()\n",
    "            #increase total for keeping track\n",
    "            total += 1\n",
    "            #if item has images, appends relevant info to appropriate dictionary list\n",
    "            if item['primaryImage'] != '':\n",
    "                image_items['id'].append(i)\n",
    "                image_items['link'].append(item['primaryImage'])\n",
    "                image_items['other_links'].append(item['additionalImages'])\n",
    "        except:\n",
    "            #if there is an error, return dictionary so it can be saved\n",
    "            #print total for reference for restarting \n",
    "            return image_items\n",
    "            print(total)\n",
    "            break\n",
    "    return image_items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggregate-pharmacology",
   "metadata": {},
   "outputs": [],
   "source": [
    "#utility function to transfer dictionaries to DataFrames and then save them as csv for safe keeping\n",
    "def data_saver(data_dict, csv_number):\n",
    "    df = pd.DataFrame(series_1)\n",
    "    df.to_csv(f'contains_images_object_ids{csv_number}.csv')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mounted-soccer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#example of two functions from above working in unison to scrape and then save data\n",
    "scrape_1 = get_object_with_info(0)\n",
    "df_1 = data_saver(scrape_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fewer-bobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "#once all data is scraped, it is stored in a postgres table \n",
    "#first step is to collect all the data stored in csv\n",
    "data_list = [i for i in os.listdir() if i.startswith('contains_images_object_ids')]\n",
    "#create DataFrame from first csv that all the others can be added to afterwards\n",
    "all_data = pd.read_csv(data_list[0])\n",
    "#iterate through other csvs and add to first\n",
    "for csv in data_list[1:]:\n",
    "    addition = pd.read_csv(csv)\n",
    "    all_data = all_data.append(addition, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "psychological-parker",
   "metadata": {},
   "outputs": [],
   "source": [
    "#establish postgres connection settings\n",
    "db_user = 'postgres'\n",
    "db_password = ''\n",
    "db_host = 'localhost'\n",
    "db_port = 5432\n",
    "database = 'met_data'\n",
    "\n",
    "conn_str = f'postgresql://{db_user}:{db_password}@{db_host}:{db_port}/{database}'\n",
    "conn = psycopg2.connect(conn_str)\n",
    "conn.autocommit = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-catalyst",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create connection and save data as postgres table\n",
    "engine = create_engine(conn_str)\n",
    "all_data.to_sql('image_url', engine)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
